{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "IlqliX9gdv8D",
    "outputId": "f98cb9d3-dad6-4e42-b5fe-99adc6278c4a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/johnmollas/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/johnmollas/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n",
    "#####################################################################\n",
    "#                Generalising on Binary Level                       #\n",
    "#####################################################################\n",
    "\n",
    "\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "from utilities.preprocess import Preproccesor\n",
    "from utilities.attention_layer import Attention\n",
    "from utilities.helping_functions import create_embedding_matrix\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import f1_score, balanced_accuracy_score, confusion_matrix\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import GlobalAveragePooling1D, GlobalMaxPooling1D, SpatialDropout1D, Bidirectional, Dense, \\\n",
    "    LSTM, Conv1D, Dropout, concatenate\n",
    "from keras import Input, Model\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading ETHOS and the dataset D1: Davidson, Thomas, et al. \"Automated hate speech detection and the problem of offensive language.\" Proceedings of the International AAAI Conference on Web and Social Media. Vol. 11. No. 1. 2017."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = Preproccesor.load_data(True)\n",
    "X_tweets, y_tweets = Preproccesor.load_external_data(True)\n",
    "class_names = ['noHateSpeech', 'hateSpeech']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset contains 24783 instances, with 1430 containing hate speech content. Thus it can be considered imbalanced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24783, 1430, 23353)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_tweets), sum(y_tweets), len(y_tweets)-sum(y_tweets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's print some statistics for tweets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "417"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cou = 0\n",
    "for k in range(len(y_tweets)):\n",
    "    if y_tweets[k] == 1:\n",
    "        if 'faggot' in X_tweets[k].lower() or 'fag' in X_tweets[k].lower() or 'gay' in X_tweets[k].lower() or 'queer' in X_tweets[k].lower():\n",
    "            cou = cou + 1\n",
    "cou"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tweets related to sexuality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "352"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cou = 0\n",
    "for k in range(len(y_tweets)):\n",
    "    if y_tweets[k] == 1:\n",
    "        if 'bitch' in X_tweets[k].lower() or 'cunt' in X_tweets[k].lower() or 'hoe' in X_tweets[k].lower():\n",
    "            cou = cou + 1\n",
    "cou"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tweets related to gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "378"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cou = 0\n",
    "for k in range(len(y_tweets)):\n",
    "    if y_tweets[k] == 1:\n",
    "        if 'nigger' in X_tweets[k].lower() or 'nigga' in X_tweets[k].lower() or 'niggu' in X_tweets[k].lower():\n",
    "            cou = cou + 1\n",
    "cou"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tweets related to race"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Now let's train a model using the ETHOS and test on D1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=10)\n",
    "kf.get_n_splits(X)\n",
    "\n",
    "f1ethos = []\n",
    "f1ethosH = []\n",
    "f1ethosNH = []\n",
    "f1tweets = []\n",
    "f1tweetsH = []\n",
    "f1tweetsNH = []\n",
    "accethos = []\n",
    "acctweets = []\n",
    "\n",
    "for train_index, test_index in kf.split(X):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "    vec = TfidfVectorizer(\n",
    "        analyzer='word', ngram_range=(1, 5), max_features=50000)\n",
    "    vec.fit(X_train)\n",
    "    X_tr = vec.transform(X_train)\n",
    "    X_te = vec.transform(X_test)\n",
    "    X_tw = vec.transform(X_tweets)\n",
    "    svm = SVC(kernel='rbf')\n",
    "    svm.fit(X_tr, y_train)\n",
    "\n",
    "    y_predict = svm.predict(X_te)\n",
    "    accethos.append(balanced_accuracy_score(y_test, y_predict))  # y_tweets\n",
    "    f1ethos.append(f1_score(y_test, y_predict, average='weighted'))\n",
    "    f1ethosNH.append(f1_score(y_test, y_predict, average=None)[0])\n",
    "    f1ethosH.append(f1_score(y_test, y_predict, average=None)[1])\n",
    "\n",
    "    y_predict = svm.predict(X_tw)\n",
    "    acctweets.append(balanced_accuracy_score(y_tweets, y_predict))  # y_tweets\n",
    "    f1tweets.append(f1_score(y_tweets, y_predict, average='weighted'))\n",
    "    f1tweetsNH.append(f1_score(y_tweets, y_predict, average=None)[0])\n",
    "    f1tweetsH.append(f1_score(y_tweets, y_predict, average=None)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 on Ethos 0.5640485977487757\n",
      "F1 Hate on Ethos 0.3320765493730913\n",
      "F1 NoHate on Ethos 0.7403227437632174\n",
      "F1 on D1 0.8732391902132248\n",
      "F1 Hate on D1 0.12845200597648176\n",
      "F1 NoHate on D1 0.9188455651311601\n",
      "Bal. Accuracy on Ethos 0.580236017196485\n",
      "Bal. Accuracy on D1 0.5402848423361848\n"
     ]
    }
   ],
   "source": [
    "print('F1 on Ethos', np.array(f1ethos).mean())\n",
    "print('F1 Hate on Ethos', np.array(f1ethosH).mean())\n",
    "print('F1 NoHate on Ethos', np.array(f1ethosNH).mean())\n",
    "print('F1 on D1', np.array(f1tweets).mean())\n",
    "print('F1 Hate on D1', np.array(f1tweetsH).mean())\n",
    "print('F1 NoHate on D1', np.array(f1tweetsNH).mean())\n",
    "print('Bal. Accuracy on Ethos', np.array(accethos).mean())\n",
    "print('Bal. Accuracy on D1', np.array(acctweets).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's train a model using the D1 and test on ETHOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=10)\n",
    "kf.get_n_splits(X_tweets)\n",
    "\n",
    "f1ethos = []\n",
    "f1ethosH = []\n",
    "f1ethosNH = []\n",
    "f1tweets = []\n",
    "f1tweetsH = []\n",
    "f1tweetsNH = []\n",
    "accethos = []\n",
    "acctweets = []\n",
    "\n",
    "for train_index, test_index in kf.split(X_tweets):\n",
    "    X_train, X_test = X_tweets[train_index], X_tweets[test_index]\n",
    "    y_train, y_test = y_tweets[train_index], y_tweets[test_index]\n",
    "\n",
    "    vec = TfidfVectorizer(\n",
    "        analyzer='word', ngram_range=(1, 5), max_features=50000)\n",
    "    vec.fit(X_train)\n",
    "    X_tr = vec.transform(X_train)\n",
    "    X_te = vec.transform(X_test)\n",
    "    X_et = vec.transform(X)\n",
    "    svm = SVC(kernel='rbf')\n",
    "    svm.fit(X_tr, y_train)\n",
    "\n",
    "    y_predict = svm.predict(X_te)\n",
    "    acctweets.append(balanced_accuracy_score(y_test, y_predict))\n",
    "    f1tweets.append(f1_score(y_test, y_predict, average='weighted'))\n",
    "    f1tweetsNH.append(f1_score(y_test, y_predict, average=None)[0])\n",
    "    f1tweetsH.append(f1_score(y_test, y_predict, average=None)[1])\n",
    "\n",
    "    y_predict = svm.predict(X_et)\n",
    "    accethos.append(balanced_accuracy_score(y, y_predict))\n",
    "    f1ethos.append(f1_score(y, y_predict, average='weighted'))\n",
    "    f1ethosNH.append(f1_score(y, y_predict, average=None)[0])\n",
    "    f1ethosH.append(f1_score(y, y_predict, average=None)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 on D1 0.9230500903911796\n",
      "F1 Hate on D1 0.12385936302731079\n",
      "F1 NoHate on D1 0.9710236819316258\n",
      "F1 on Ethos 0.4266857670626746\n",
      "F1 Hate on Ethos 0.03534806560292477\n",
      "F1 NoHate on Ethos 0.7265958993318281\n",
      "Bal. Accuracy on D1 0.5333261046305611\n",
      "Bal. Accuracy on Ethos 0.5090069284064666\n"
     ]
    }
   ],
   "source": [
    "print('F1 on D1', np.array(f1tweets).mean())\n",
    "print('F1 Hate on D1', np.array(f1tweetsH).mean())\n",
    "print('F1 NoHate on D1', np.array(f1tweetsNH).mean())\n",
    "print('F1 on Ethos', np.array(f1ethos).mean())\n",
    "print('F1 Hate on Ethos', np.array(f1ethosH).mean())\n",
    "print('F1 NoHate on Ethos', np.array(f1ethosNH).mean())\n",
    "print('Bal. Accuracy on D1', np.array(acctweets).mean())\n",
    "print('Bal. Accuracy on Ethos', np.array(accethos).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, it would be interesting to investigate the overall performance of an SVMmodel trained on a combination dataset of those two"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=10, shuffle=True, random_state=7)\n",
    "\n",
    "X_NEW = np.concatenate((X, X_tweets))\n",
    "y_NEW = np.concatenate((y, y_tweets))\n",
    "kf.get_n_splits(X_NEW)\n",
    "\n",
    "f1 = []\n",
    "f1H = []\n",
    "f1NH = []\n",
    "acc = []\n",
    "\n",
    "for train_index, test_index in kf.split(X_NEW):\n",
    "    X_train, X_test = X_NEW[train_index], X_NEW[test_index]\n",
    "    y_train, y_test = y_NEW[train_index], y_NEW[test_index]\n",
    "\n",
    "    vec = TfidfVectorizer(\n",
    "        analyzer='word', ngram_range=(1, 5), max_features=50000)\n",
    "    vec.fit(X_train)\n",
    "    X_tr = vec.transform(X_train)\n",
    "    X_te = vec.transform(X_test)\n",
    "    svm = SVC(kernel='rbf')\n",
    "    svm.fit(X_tr, y_train)\n",
    "\n",
    "    y_predict = svm.predict(X_te)\n",
    "    acc.append(balanced_accuracy_score(y_test, y_predict))  # y_tweets\n",
    "    f1.append(f1_score(y_test, y_predict, average='weighted'))\n",
    "    f1NH.append(f1_score(y_test, y_predict, average=None)[0])\n",
    "    f1H.append(f1_score(y_test, y_predict, average=None)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 on Both 0.9083655535830211\n",
      "F1 Hate on Both 0.18481107803210042\n",
      "F1 NoHate on Both 0.9647914678552706\n",
      "Bal. Accuracy on Both 0.5516466691239722\n"
     ]
    }
   ],
   "source": [
    "print('F1 on Both', np.array(f1).mean())\n",
    "print('F1 Hate on Both', np.array(f1H).mean())\n",
    "print('F1 NoHate on Both', np.array(f1NH).mean())\n",
    "print('Bal. Accuracy on Both', np.array(acc).mean())"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "CNN+Class.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
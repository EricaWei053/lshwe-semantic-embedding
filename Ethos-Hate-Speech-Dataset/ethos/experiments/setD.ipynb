{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hR3FalYEjxU3"
   },
   "source": [
    "<table class=\"tfo-notebook-buttons\" align=\"center\">\n",
    "  <tr>   \n",
    "    <th>\n",
    "      <a target=\"_blank\" href=\"https://colab.research.google.com/github.com/iamollas/hateSpeechDataV2/blob/master/setD.ipynb\"> <img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\"/></a>\n",
    "    </th>\n",
    "    <th>\n",
    "      <a target=\"_blank\" href=\"https://github.com/iamollas/hateSpeechDataV2/blob/master/setD.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\"/></a>\n",
    "    </th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <th>\n",
    "      <a target=\"_blank\" href=\"https://colab.research.google.com/github.com/iamollas/hateSpeechDataV2/blob/master/setD.ipynb\">\n",
    "      Run in Google Colab</a>\n",
    "    </th>\n",
    "    <th>\n",
    "      <a target=\"_blank\" href=\"https://github.com/iamollas/hateSpeechDataV2/blob/master/setD.ipynb\">\n",
    "      View source on GitHub</a>\n",
    "    </th>\n",
    "  </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RIddtfgDmk6Y"
   },
   "source": [
    "Do you plan to test it on Colab? Make sure you change your settings to: Runtime->Change runtime type->Hardware accelarator->GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "snUCpRg7rMAo"
   },
   "source": [
    "We import some necessary libraries and we load our hate speech dataset.\n",
    "The preprocess script is available on the github repo.\n",
    "\n",
    "Check code here: https://towardsdatascience.com/how-to-do-text-binary-classification-with-bert-f1348a25d905"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 86
    },
    "colab_type": "code",
    "id": "jyu3Ehl9Hpoi",
    "outputId": "e010f026-4f5b-4288-f279-b97eab05c710"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.6 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.7\n",
      "  return f(*args, **kwds)\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/johnmollas/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/johnmollas/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n",
    "#####################################################################\n",
    "#                           Set D                                   #\n",
    "#####################################################################\n",
    "#                        BERT Tests                                 #\n",
    "\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n",
    "import tensorflow as tf\n",
    "import nltk\n",
    "import numpy as np\n",
    "import time\n",
    "from sklearn.metrics import confusion_matrix, f1_score, accuracy_score, precision_score, recall_score\n",
    "from utilities.preprocess import Preproccesor\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "pd.set_option('max_colwidth', 400)\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "X, y = Preproccesor.load_data(True)\n",
    "class_names = ['noHateSpeech', 'hateSpeech']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1aNBBGtMrknU"
   },
   "source": [
    "We want to measure specificity and sensitivity, so we manually create those two functions for these metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "5cqoKzC2_faU"
   },
   "outputs": [],
   "source": [
    "def specificity(tn, fp, fn, tp):\n",
    "    tn, fp, fn, tp\n",
    "    if(tn+fp) > 0:\n",
    "        speci = tn/(tn+fp)\n",
    "        return speci\n",
    "    return 0\n",
    "\n",
    "\n",
    "def sensitivity(tn, fp, fn, tp):\n",
    "    tn, fp, fn, tp\n",
    "    if(tp+fn) > 0:\n",
    "        sensi = tp/(tp+fn)\n",
    "        return sensi\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WEr8_weUr_FU"
   },
   "source": [
    "More over, for our bert experiments we will need the bert-text library in order to have more compact code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 713
    },
    "colab_type": "code",
    "id": "EQHcJlAgHZ2o",
    "outputId": "3d88b5e8-7461-4928-830c-b1eee0db9e5b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting bert_text\n",
      "\u001b[31m  Could not find a version that satisfies the requirement bert_text (from versions: )\u001b[0m\n",
      "\u001b[31mNo matching distribution found for bert_text\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install bert_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bJ7qG9yOsBHQ"
   },
   "source": [
    "Now we our testing with a 10-Fold Cross Validation process the BERT's performance. In every loop we load BERT and we perform fine tuning using the new train sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "UJZwZjvYc0Dx"
   },
   "outputs": [],
   "source": [
    "  !rm '/content/test.tsv'\n",
    "  !rm '/content/train.tsv'\n",
    "  !rm -R '/content/output'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 193
    },
    "colab_type": "code",
    "id": "EZPKf9PaHgcW",
    "outputId": "79fb8ec0-381b-4cf1-d377-4c7fd567430b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0 started at Thu Sep 12 16:50:09 2019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gradients_util.py:93: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gradients_util.py:93: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 {'auc': 0.7444179, 'eval_accuracy': 0.75247526, 'f1_score': 0.70588225, 'false_negatives': 14.0, 'false_positives': 11.0, 'loss': 1.3915498, 'precision': 0.73170733, 'recall': 0.6818182, 'true_negatives': 46.0, 'true_positives': 30.0, 'global_step': 560}\n",
      "Fold 1 started at Thu Sep 12 16:59:12 2019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gradients_util.py:93: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    }
   ],
   "source": [
    "f_results = []\n",
    "n_fold = 10\n",
    "folds = StratifiedKFold(n_splits=n_fold, shuffle=True, random_state=7)\n",
    "counter = 0\n",
    "for fold_n, (train_index, valid_index) in enumerate(folds.split(X, y)):\n",
    "    from bert_text import run_on_dfs\n",
    "    print('Fold', fold_n, 'started at', time.ctime())\n",
    "    X_train, X_test = X[train_index], X[valid_index]\n",
    "    y_train, y_test = y[train_index], y[valid_index]\n",
    "    ids = []\n",
    "    idsT = []\n",
    "    for i in range(0, len(X_train)):\n",
    "        ids.append(i)\n",
    "    for i in range(0, len(X_test)):\n",
    "        idsT.append(i)\n",
    "    train = pd.DataFrame(X_train, columns=['comment_text'], index=ids)\n",
    "    train['target'] = y_train\n",
    "    test = pd.DataFrame(X_test, columns=['comment_text'], index=idsT)\n",
    "    test['target'] = y_test\n",
    "    train.to_csv('train.tsv', sep='\\t', index=False, header=False)\n",
    "    test.to_csv('test.tsv', sep='\\t', index=False, header=True)\n",
    "    myparam = {\n",
    "        \"DATA_COLUMN\": \"comment_text\",\n",
    "        \"LABEL_COLUMN\": \"target\",\n",
    "        \"MAX_SEQ_LENGTH\": 100,\n",
    "        \"BATCH_SIZE\": 16,\n",
    "        \"LEARNING_RATE\": 2e-5,\n",
    "        \"NUM_TRAIN_EPOCHS\": 10,\n",
    "        \"SAVE_SUMMARY_STEPS\": 100,  # 100\n",
    "        \"SAVE_CHECKPOINTS_STEPS\": 10000  # 10000\n",
    "    }\n",
    "    result, estimator = run_on_dfs(train, test, **myparam)\n",
    "    f_results.append(result)\n",
    "    print(len(f_results), result)\n",
    "    del result, estimator\n",
    "    !rm '/content/test.tsv'\n",
    "    !rm '/content/train.tsv'\n",
    "    !rm - R '/content/output'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ApYbEwoVvFIR"
   },
   "source": [
    "Finally, we compute the metrics we want and we save them to a txt file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "69vwNde1c-2q"
   },
   "outputs": [],
   "source": [
    "acc = 0\n",
    "f1 = 0\n",
    "sensi = 0\n",
    "speci = 0\n",
    "preci = 0\n",
    "recall = 0\n",
    "for i in f_results:\n",
    "    tn = i['true_negatives']\n",
    "    fp = i['false_positives']\n",
    "    fn = i['false_negatives']\n",
    "    tp = i['true_positives']\n",
    "    acc = acc + i['eval_accuracy']\n",
    "    f1 = f1 + i['f1_score']\n",
    "    preci = preci + i['precision']\n",
    "    recall = recall + i['recall']\n",
    "    speci = speci + specificity(tn, fp, fn, tp)\n",
    "    sensi = sensi + sensitivity(tn, fp, fn, tp)\n",
    "print(\"{:<7} | {:<7} {:<7} {:<7} {:<7} {:<7} {:<7}\".format(\n",
    "    'Method', 'F1score', 'Precisi', 'Recall', 'Accurac', 'Specifi', 'Sensiti'))\n",
    "print(\"=========================================================================\")\n",
    "print(\"{:<7} | {:<7} {:<7} {:<7} {:<7} {:<7} {:<7}\".format(str(\"BERT\")[:7], str('%.4f' % (f1/10)), str('%.4f' % (preci/10)),\n",
    "                                                           str('%.4f' % (\n",
    "                                                               recall/10)), str('%.4f' % (acc/10)), str('%.4f' % (speci/10)),\n",
    "                                                           str('%.4f' % (sensi/10))))\n",
    "f = open(\"setD.txt\", \"a+\")\n",
    "f.write(\"{:<7} | {:<7} {:<7} {:<7} {:<7} {:<7} {:<7}\".format(\n",
    "    'Method', 'F1score', 'Precisi', 'Recall', 'Accurac', 'Specifi', 'Sensiti'))\n",
    "f.write(\"=========================================================================\\n\")\n",
    "f.write(\"{:<7} | {:<7} {:<7} {:<7} {:<7} {:<7} {:<7}\".format(str(\"BERT\")[:7], str('%.4f' % (f1/10)), str('%.4f' % (preci/10)),\n",
    "                                                             str('%.4f' % (\n",
    "                                                                 recall/10)), str('%.4f' % (acc/10)), str('%.4f' % (speci/10)),\n",
    "                                                             str('%.4f' % (sensi/10))))\n",
    "f.close()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "BertFinally.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}